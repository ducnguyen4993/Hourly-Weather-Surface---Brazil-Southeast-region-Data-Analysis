{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/hourly-weather-surface-brazil-southeast-region/sudeste.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style('darkgrid')\nplt.rcParams[\"patch.force_edgecolor\"] = True\n","execution_count":2,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_original = pd.read_csv(\"/kaggle/input/hourly-weather-surface-brazil-southeast-region/sudeste.csv\", chunksize=98000)\n# df = pd.concat(df_original)","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dataset is too big so lets import in a chunk and work with the smallest one at first"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_coll = [df for df in df_original]","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smallest_df = df_coll[-1].copy()","execution_count":10,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Info On Some Columns\n\n\n1. Instant Air Temperature (celsius degrees) = temp\n2. Maximum Air Temperature (celsius degrees) = tmin\n3. Minimum Air Temperature (celsius degrees) = tmax\n4. Relative Humidity of Air (%) =hmdy\n5. Maximum Relative Air Humidity (%) =hmax\n6. Minimum Relative Air Humidity (%) = hmin\n7. Instant Dew Point (celsius degrees) = dewp\n8. Maximum Dew Point (celsius degrees)=dmax\n9. Minimum Dew Point Temperature (celsius degrees) = dmin\n10. Instant Air Atmospheric Pressure (millibars) =stp\n11. Maximum Air Atmospheric Pressure (millibars) = smax\n12. Minimum Air Atmospheric Pressure (millibars)= smin\n13. Instant Wind Speed (metres per second) = wdsp\n14. Wind Direction (radius degrees) = wdct\n15. Wind Gust Intensity (metres per second) = gust\n16. Solar radiation  =  gbrd\n17. Precipitation (milimetres) = prcp\n18. Elevation = elvt\n19. Observation Datetime = mdct\n20. Observation Date = date\n21. Station number (INMET number) for the location = inme\n22. The year (2000-2016) : yr\n23. The month (0-12) : mo\n24. The day (0-31): da\n25. The hour : hr\n\n*Not all the columns are mentioned in this list*"},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(df.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(smallest_df.info())","execution_count":11,"outputs":[{"output_type":"stream","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 77168 entries, 9702000 to 9779167\nData columns (total 31 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   wsid    77168 non-null  int64  \n 1   wsnm    77168 non-null  object \n 2   elvt    77168 non-null  float64\n 3   lat     77168 non-null  float64\n 4   lon     77168 non-null  float64\n 5   inme    77168 non-null  object \n 6   city    77168 non-null  object \n 7   prov    77168 non-null  object \n 8   mdct    77168 non-null  object \n 9   date    77168 non-null  object \n 10  yr      77168 non-null  int64  \n 11  mo      77168 non-null  int64  \n 12  da      77168 non-null  int64  \n 13  hr      77168 non-null  int64  \n 14  prcp    8255 non-null   float64\n 15  stp     77168 non-null  float64\n 16  smax    77168 non-null  float64\n 17  smin    77168 non-null  float64\n 18  gbrd    45016 non-null  float64\n 19  temp    77168 non-null  float64\n 20  dewp    77164 non-null  float64\n 21  tmax    77168 non-null  float64\n 22  dmax    77167 non-null  float64\n 23  tmin    77168 non-null  float64\n 24  dmin    77162 non-null  float64\n 25  hmdy    77168 non-null  float64\n 26  hmax    77168 non-null  float64\n 27  hmin    77168 non-null  float64\n 28  wdsp    77168 non-null  float64\n 29  wdct    77168 non-null  float64\n 30  gust    77168 non-null  float64\ndtypes: float64(20), int64(5), object(6)\nmemory usage: 18.3+ MB\nNone\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Tidying Data"},{"metadata":{},"cell_type":"markdown","source":"## Drop Elvt,Lat and Long"},{"metadata":{},"cell_type":"markdown","source":" Lat and long can correlate to city and province, so, remove elevation, longitude and lattitude "},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.drop(['lat','lon', 'elvt'],inplace=True, axis=1)\nsmallest_df.drop(['lat','lon', 'elvt'], axis=1,inplace=True)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(smallest_df.iloc[:,:10].head(1))\nprint(\"==\"*20)\nprint(smallest_df.iloc[:,10:20].head(1))\nprint(\"==\"*20)\n\nprint(smallest_df.iloc[:,20:].head(1))","execution_count":14,"outputs":[{"output_type":"stream","text":"         wsid       wsnm  inme       city prov                 mdct  \\\n9702000   422  ITUVERAVA  A753  Ituverava   SP  2013-06-16 16:00:00   \n\n               date    yr  mo  da  \n9702000  2013-06-16  2013   6  16  \n========================================\n         hr  prcp    stp   smax   smin      gbrd  temp  dewp  tmax  dmax\n9702000  16   0.0  944.3  945.5  944.3  2346.659  27.9  13.7  28.2  14.7\n========================================\n         tmin  dmin  hmdy  hmax  hmin  wdsp   wdct  gust\n9702000  27.1  13.2  42.0  46.0  40.0   3.8  332.0   9.5\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop the weather station name since its being represented as wsid\n\n\nsmallest_df.drop('wsnm', axis=1,inplace=True)","execution_count":16,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Drop Multiple Time related columns"},{"metadata":{},"cell_type":"markdown","source":"There are five columns on time of observatoin. They are mdct, date,yr, month and hour, which are same but separated into several sctions. Among them Date and Hour columns are useful and represent all in some form, so others can be dropped. The conversion of date column to datetime gave format error. So, first lets combine the yr,mo,da and hr columns to make one and then drop them"},{"metadata":{"trusted":true},"cell_type":"code","source":"smallest_df['date']=pd.to_datetime(smallest_df[['yr', 'mo', 'da','hr']].rename(columns={'yr': 'year','mo': 'month','da': 'day','hr':'hour'}))","execution_count":32,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smallest_df.drop(['mdct','yr','da','mo'], axis= 1, inplace=True)","execution_count":33,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reset Index as Date column and the check for duplicates data on same date in same city and remove them"},{"metadata":{"trusted":true},"cell_type":"code","source":"smallest_df.set_index('date',inplace=True,drop=True)","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smallest_df.duplicated('city')","execution_count":37,"outputs":[{"output_type":"execute_result","execution_count":37,"data":{"text/plain":"date\n2013-06-16 16:00:00    False\n2013-06-16 17:00:00     True\n2013-06-16 18:00:00     True\n2013-06-16 19:00:00     True\n2013-06-16 20:00:00     True\n                       ...  \n2016-09-30 19:00:00     True\n2016-09-30 20:00:00     True\n2016-09-30 21:00:00     True\n2016-09-30 22:00:00     True\n2016-09-30 23:00:00     True\nLength: 77168, dtype: bool"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Since there is no null values,under the assumption that all the data from various weather stations are valid and true, lets not filter the time of operation of weather stations and drop the wsids and inme, only city adn prov are enough."},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.drop(['wsid','inme'], inplace=True, axis=1)\nsmallest_df.drop(['wsid','inme'],inplace=True, axis=1)","execution_count":36,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"\"['wsid' 'inme'] not found in axis\"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-807f764f6e4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# df.drop(['wsid','inme'], inplace=True, axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msmallest_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'wsid'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'inme'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3995\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3996\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3997\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3998\u001b[0m         )\n\u001b[1;32m   3999\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3934\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3935\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3936\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3938\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3968\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3970\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3971\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5015\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5017\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5018\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5019\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"['wsid' 'inme'] not found in axis\""]}]},{"metadata":{},"cell_type":"markdown","source":"# Exploration and Manipulation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # print(df['wsid'].unique())\n# print(df['wsid'].value_counts(normalize=True)*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(df['city'].unique())\n# print(df['city'].value_counts(normalize=True)*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df['prov'].value_counts(normalize=True).plot.pie(figsize=(8,10),autopct = '%.1f%%',labels=['Minas Gerais','São Paulo','Rio de Janeiro','Espírito Santo'])\n# plt.xlabel(\" \")\n# plt.ylabel(\" \")\n# # plt.legend(['Minas Gerais','São Paulo','Rio de Janeiro','Espírito Santo'], loc=0)\n# plt.title('Weather Data by Province')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smallest_df.isnull().sum()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}